{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Experiment 2: Adding Semantic Embeddings\n",
        "\n",
        "\n",
        "Previous experiment got 26% with just TF-IDF. That's better than random but not good enough.\n",
        "\n",
        "**Idea:** Maybe semantic embeddings can capture meaning better?\n",
        "- \"collaborate\" should match \"teamwork\"\n",
        "- \"Java\" should match \"programming\"\n",
        "\n",
        "Let's try Sentence-BERT!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from sentence_transformers import SentenceTransformer\n",
        "\n",
        "df = pd.read_csv('../data/shl_individual_test_solutions.csv')\n",
        "train_df = pd.read_excel('../data/Gen_AI Dataset (1).xlsx', sheet_name='Train-Set')\n",
        "\n",
        "# URL normalization\n",
        "df['normalized_url'] = df['url'].str.replace('/solutions/products/', '/products/')\n",
        "train_df['normalized_url'] = train_df['Assessment_url'].str.replace('/solutions/products/', '/products/')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load embedding model\n",
        "# Using MiniLM - supposed to be good for similarity\n",
        "print(\"Loading model...\")\n",
        "model = SentenceTransformer('all-MiniLM-L6-v2')\n",
        "print(\"Model loaded!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create richer text for embeddings\n",
        "texts = []\n",
        "for _, row in df.iterrows():\n",
        "    text = f\"{row['name']}. {row['description']}.\"\n",
        "    texts.append(text)\n",
        "\n",
        "print(f\"Encoding {len(texts)} texts...\")\n",
        "embeddings = model.encode(texts, show_progress_bar=True)\n",
        "print(f\"Embeddings shape: {embeddings.shape}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Test semantic similarity\n",
        "\n",
        "Let's see if \"collaborate\" matches personality tests..."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [],
      "source": [
        "query = \"developer who collaborates\"\n",
        "query_emb = model.encode([query])\n",
        "semantic_scores = cosine_similarity(query_emb, embeddings)[0]\n",
        "\n",
        "top_10_idx = np.argsort(semantic_scores)[-10:][::-1]\n",
        "\n",
        "print(f\"Top 10 semantic matches for '{query}':\")\n",
        "for i, idx in enumerate(top_10_idx, 1):\n",
        "    print(f\"{i}. {df.iloc[idx]['name']} (score: {semantic_scores[idx]:.3f})\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Interesting!** Getting some personality tests now (OPQ, etc.)\n",
        "\n",
        "But losing some technical tests...\n",
        "\n",
        "**Idea:** Combine TF-IDF + Semantic?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Build TF-IDF too\n",
        "documents = [f\"{row['name']} {row['description']}\" for _, row in df.iterrows()]\n",
        "vectorizer = TfidfVectorizer(max_features=5000, ngram_range=(1, 2))\n",
        "tfidf_matrix = vectorizer.fit_transform(documents)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Evaluate with hybrid: 50% TF-IDF + 50% Semantic\n",
        "recalls = []\n",
        "\n",
        "for query, group in train_df.groupby('Query'):\n",
        "    ground_truth = set(group['normalized_url'])\n",
        "    \n",
        "    # TF-IDF scores\n",
        "    query_vec = vectorizer.transform([query])\n",
        "    tfidf_scores = cosine_similarity(query_vec, tfidf_matrix)[0]\n",
        "    \n",
        "    # Semantic scores\n",
        "    query_emb = model.encode([query])\n",
        "    semantic_scores = cosine_similarity(query_emb, embeddings)[0]\n",
        "    \n",
        "    # Combine (trying 50-50 split)\n",
        "    combined_scores = 0.5 * tfidf_scores + 0.5 * semantic_scores\n",
        "    \n",
        "    top_10_idx = np.argsort(combined_scores)[-10:][::-1]\n",
        "    predicted = set(df.iloc[top_10_idx]['normalized_url'])\n",
        "    \n",
        "    found = len(ground_truth & predicted)\n",
        "    recall = found / len(ground_truth) if len(ground_truth) > 0 else 0\n",
        "    recalls.append(recall)\n",
        "    \n",
        "    print(f\"Recall: {recall:.2f} | Query: {query[:60]}...\")\n",
        "\n",
        "mean_recall = np.mean(recalls)\n",
        "print(f\"\\nMean Recall@10: {mean_recall:.3f} ({mean_recall*100:.1f}%)\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Results: 32.8% Mean Recall@10\n",
        "\n",
        "**Better!** (+6.6% from baseline)\n",
        "\n",
        "But still not great... only 33% recall\n",
        "\n",
        "**Observations:**\n",
        "- Semantic helps with synonyms\n",
        "- TF-IDF helps with exact matches\n",
        "- Combination is better than either alone\n",
        "- But still missing context...\n",
        "\n",
        "**Next ideas:**\n",
        "- Use LLM to understand query better?\n",
        "- Learn from training data patterns?\n",
        "- Weight fields differently (name more important than description?)\n",
        "\n",
        "Will try LLM next..."
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}