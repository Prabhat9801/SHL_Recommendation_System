# Render Deployment Guide - Pre-Download Models

## üéØ What Changed?

**Problem:** Models were downloading when users made queries (causing 500MB+ downloads and memory issues)

**Solution:** Models now download **during deployment** (build time), not at runtime!

---

## üì¶ How It Works

### 1. **Build Phase (Happens Once During Deployment)**
```bash
pip install -r requirements.txt && python download_models.py
```
- Installs all dependencies
- **Downloads sentence-transformers model** (~500MB)
- Caches model in `.model_cache/` directory
- ‚úÖ Model ready before app starts

### 2. **Runtime Phase (When App Is Live)**
```bash
uvicorn backend.main:app --host 0.0.0.0 --port $PORT
```
- App starts with **pre-downloaded model**
- User queries use **cached model** (no downloads!)
- ‚úÖ Fast responses, no memory spikes

---

## üöÄ Deployment Steps

### On Render Dashboard:

1. **Create New Web Service**
   - Connect your GitHub repository

2. **Environment Variables** (Set these in Render dashboard)
   ```
   GROQ_API_KEY=your_groq_api_key_here
   PYTHON_VERSION=3.10.13
   TRANSFORMERS_CACHE=/opt/render/project/src/.model_cache
   SENTENCE_TRANSFORMERS_HOME=/opt/render/project/src/.model_cache
   ```

3. **Build & Start Commands** (Auto-detected from render.yaml)
   - **Build Command:** `pip install -r requirements.txt && python download_models.py`
   - **Start Command:** `uvicorn main:app --host 0.0.0.0 --port $PORT`

4. **Deploy!**
   - Render will run the build command
   - Model downloads during build (visible in logs)
   - App starts with cached model

---

## üìã Files Modified

1. **`download_models.py`** - New script to pre-download models
2. **`modules/feature_extractor.py`** - Updated to use cached models
3. **`render.yaml`** - Added build command with model download
4. **`.gitignore`** - Added `.model_cache/` directory

---

## ‚úÖ What to Expect in Deployment Logs

### During Build:
```
========================================
DOWNLOADING REQUIRED MODELS FOR DEPLOYMENT
========================================

üì¶ Downloading model: all-MiniLM-L6-v2
üìÅ Cache directory: /opt/render/project/src/.model_cache
----------------------------------------
Downloading model files...
[Progress bars showing ~500MB download]
----------------------------------------
‚úÖ Model 'all-MiniLM-L6-v2' downloaded successfully!
üìä Model cached at: /opt/render/project/src/.model_cache

üß™ Testing model...
‚úÖ Model test successful! Embedding shape: (1, 384)

========================================
‚úÖ ALL MODELS DOWNLOADED SUCCESSFULLY
========================================
```

### When App Starts:
```
INFO:     Started server process [1]
INFO:     Waiting for application startup.
INFO:     Application startup complete.
INFO:     Uvicorn running on http://0.0.0.0:8000
```

### When User Makes First Query:
```
Initializing modular recommendation engine...
Loading embedding model: all-MiniLM-L6-v2
‚úÖ Loading from cache (NO DOWNLOAD!)
‚úÖ Recommendation engine ready!
```

---

## üß™ Test Locally

```bash
# Install dependencies
pip install -r requirements.txt

# Download models (one-time)
python download_models.py

# Start the server
uvicorn main:app --host 0.0.0.0 --port 8000

# Test the endpoint
curl -X POST http://localhost:8000/recommend \
  -H "Content-Type: application/json" \
  -d '{"query": "Software Developer with Python skills", "top_k": 5}'
```

---

## üí° Key Benefits

1. ‚úÖ **No runtime downloads** - Model ready before app starts
2. ‚úÖ **Faster responses** - No delay on first query
3. ‚úÖ **Lower memory usage** - Download happens in build phase (more memory available)
4. ‚úÖ **No logic changes** - Same recommendation system, just optimized deployment
5. ‚úÖ **Build-time verification** - If model download fails, deployment fails (not at runtime)

---

## üîß Troubleshooting

### If Build Fails

**Check logs for:**
```
‚ùå Error downloading models: [error message]
```

**Solutions:**
1. Verify internet connection during build
2. Check if Render has enough memory for build
3. Model download might timeout - retry deployment

### If Model Not Found at Runtime

**Check environment variables:**
```bash
TRANSFORMERS_CACHE=/opt/render/project/src/.model_cache
SENTENCE_TRANSFORMERS_HOME=/opt/render/project/src/.model_cache
```

---

## üìù Manual Deployment (Without render.yaml)

If not using `render.yaml`, set these in Render dashboard:

**Build Command:**
```bash
pip install -r requirements.txt && python download_models.py
```

**Start Command:**
```bash
uvicorn main:app --host 0.0.0.0 --port $PORT
```

**Environment Variables:**
- `GROQ_API_KEY` = your_api_key
- `PYTHON_VERSION` = 3.10.13
- `TRANSFORMERS_CACHE` = /opt/render/project/src/.model_cache
- `SENTENCE_TRANSFORMERS_HOME` = /opt/render/project/src/.model_cache

---

## üéâ Success Indicators

‚úÖ Build logs show "ALL MODELS DOWNLOADED SUCCESSFULLY"
‚úÖ App starts without downloading models
‚úÖ First query responds quickly
‚úÖ No "Downloading model..." messages in runtime logs
‚úÖ Memory usage stays within Render's 512MB limit

---

**Your backend is now optimized for Render deployment!** üöÄ

Models download once during build, not every time a user makes a query!
